{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa2f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "121aaac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_vowel(char):\n",
    "    return char.lower() in \"aeiouyåæø\"\n",
    "\n",
    "\n",
    "def is_consonant(char):\n",
    "    return not is_vowel(char)\n",
    "\n",
    "\n",
    "def remove_short_vowel_consonant_cluster(token):\n",
    "    prev_char = token[0]\n",
    "    double_cons = False\n",
    "    offset = 0\n",
    "    for i, cur_char in enumerate(token):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if is_consonant(cur_char):\n",
    "            if cur_char == prev_char:\n",
    "                double_cons = True\n",
    "            elif double_cons:\n",
    "                if not (prev_char in \"sk\" and cur_char == \"j\"):\n",
    "                    token = token[:i - 1 - offset] + token[i - offset:]\n",
    "                    offset += 1\n",
    "                double_cons = False\n",
    "            else:\n",
    "                double_cons = False\n",
    "        else:\n",
    "            double_cons = False\n",
    "        prev_char = cur_char\n",
    "    return token\n",
    "\n",
    "        \n",
    "skip_tokens = ['#', '##', '*',  # pauses, overlaps\n",
    "               # interjections\n",
    "               'ee', 'eh', 'ehe', 'em', 'heh', 'hm', 'm', 'm-m', 'mhm', 'mm'\n",
    "               ]\n",
    "interviewers = ['ms', 'jb', 'ifg', 'rvf', 'sb', 'lks', 'mn', 'sl', 'sr',\n",
    "                'kb', 'kh', 'iii', 'eo', 'hna', 'ma', 'os', 'as', 'ov',\n",
    "                'amr', 'ran', 'mi', 'lh', 'mj', 'ahl', 'ks', 'amj', 'cbo',\n",
    "                'jbj', 'jk', 'bl', 'ta', 'pmk', 'aml', 'amg']\n",
    "lines = []\n",
    "for file in glob(\"../data/ndc_phon_with_informant_codes/files/norwegian/*.txt\"):\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            speaker, content = line.split(\" \", 1)\n",
    "            if speaker in interviewers:\n",
    "                # interviewers don't have phono transcriptions\n",
    "                continue\n",
    "            tokens_raw = content.strip().split()\n",
    "            tokens_final = []\n",
    "            for token in tokens_raw:\n",
    "                if not token or token in skip_tokens:\n",
    "                    continue\n",
    "                # Make the transcription more similar to\n",
    "                # actual writing.\n",
    "                # syllabic consonants, syllable boundaries\n",
    "                token = token.replace(\"'\", \"\")\n",
    "                \n",
    "                # Short vowels marked via consonant doubling in\n",
    "                # ways unlikely to be used in \"normal\" writing\n",
    "                token = token.replace(\"ssjt\", \"rst\")\n",
    "                token = token.replace(\"ssjk\", \"rsk\")\n",
    "                if len(token) > 3 and token not in [\"ikkje\", \"issje\"]:\n",
    "                    # NB this catches some false positives\n",
    "                    token = remove_short_vowel_consonant_cluster(token)\n",
    "                \n",
    "                # Retroflex flap\n",
    "                # \"L\" could either be \"l\" or \"rd\", but we have many more \"l\" cases\n",
    "                token = token.replace(\"L\", \"l\")\n",
    "                \n",
    "                token = token.replace(\"_\", \" \")\n",
    "                tokens_final.append(token)\n",
    "            if len(tokens_final) < 2:\n",
    "                continue\n",
    "            lines.append(\" \".join(tokens_final))\n",
    "                \n",
    "with open(\"../data/ndc_dialect.txt\", \"w+\", encoding=\"utf8\") as f:\n",
    "    for line in lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "\n",
    "lines = []\n",
    "for file in glob(\"../data/ndc_with_informant_codes/files/norwegian/*.txt\"):\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            speaker, content = line.split(\" \", 1)\n",
    "            if speaker in interviewers:\n",
    "                # interviewers don't have phono transcriptions\n",
    "                continue\n",
    "            tokens_raw = content.strip().split()\n",
    "            tokens_final = []\n",
    "            for token in tokens_raw:\n",
    "                if not token or token in skip_tokens or token == \"e\":\n",
    "                    continue\n",
    "                token = token.replace(\"_\", \" \")\n",
    "                tokens_final.append(token)\n",
    "            if len(tokens_final) < 2:\n",
    "                continue\n",
    "            lines.append(\" \".join(tokens_final))\n",
    "                \n",
    "with open(\"../data/ndc_bokmaal.txt\", \"w+\", encoding=\"utf8\") as f:\n",
    "    for line in lines:\n",
    "        f.write(line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8886b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
