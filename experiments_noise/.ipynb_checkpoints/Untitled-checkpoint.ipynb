{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b05d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a1b9c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mt/zl7rtl0s6wv29x77x1ldj5800000gn/T/ipykernel_26827/1905548161.py:37: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  return word[:idx] + random.sample(alphabet, 1)[0] + word[idx + 1:]\n",
      "/var/folders/mt/zl7rtl0s6wv29x77x1ldj5800000gn/T/ipykernel_26827/1905548161.py:26: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  return word[:idx + 1] + random.sample(alphabet, 1)[0] + word[idx + 1:]\n",
      "/var/folders/mt/zl7rtl0s6wv29x77x1ldj5800000gn/T/ipykernel_26827/1905548161.py:25: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  return random.sample(alphabet, 1)[0] + word\n"
     ]
    }
   ],
   "source": [
    "def alphabet(filename, col_idx):\n",
    "    words = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if (not line) or line[0] == \"#\":\n",
    "                continue\n",
    "            word = line.split(\"\\t\")[col_idx]\n",
    "            words.append(word)\n",
    "    return {c for word in words for c in word if c.isalpha()}\n",
    "\n",
    "\n",
    "def noisy_indices(sent_toks, percentage_noisy):\n",
    "    # Only include words with alphabetic content.\n",
    "    poss_indices = [i for i, tok in enumerate(sent_toks)\n",
    "                    if any(c.isalpha() for c in tok)]\n",
    "    idx_noisy = random.sample(\n",
    "        poss_indices, k=round(percentage_noisy * len(poss_indices)))\n",
    "    return idx_noisy\n",
    "\n",
    "\n",
    "def add_char(word, alphabet):\n",
    "    idx = random.randrange(-1, len(word))\n",
    "    if idx == -1:\n",
    "        return random.sample(alphabet, 1)[0] + word\n",
    "    return word[:idx + 1] + random.sample(alphabet, 1)[0] + word[idx + 1:]\n",
    "\n",
    "\n",
    "def delete_char(word):\n",
    "    idx = random.randrange(len(word))\n",
    "    return word[:idx] + word[idx + 1:]\n",
    "\n",
    "\n",
    "def replace_char(word, alphabet, idx=-1):\n",
    "    if idx < 0:\n",
    "        idx = random.randrange(len(word))\n",
    "    return word[:idx] + random.sample(alphabet, 1)[0] + word[idx + 1:]\n",
    "\n",
    "\n",
    "def add_random_noise(words, noise_lvl, alphabet,\n",
    "                     noise=(\"add_char\", \"delete_char\", \"replace_char\")):\n",
    "    toks_noisy = []\n",
    "    n_changed = 0\n",
    "    idx_noisy = sorted(noisy_indices(words, noise_lvl))\n",
    "    words_noisy = []\n",
    "    for i, word in enumerate(words):\n",
    "        if i in idx_noisy:\n",
    "            noise_type = random.choice(noise)\n",
    "            if noise_type == \"add_char\":\n",
    "                word_noised = add_char(word, alphabet)\n",
    "            elif noise_type == \"delete_char\":\n",
    "                word_noised = delete_char(word)\n",
    "            elif noise_type == \"replace_char\":\n",
    "                word_noised = replace_char(word, alphabet)\n",
    "            else:\n",
    "                print(\"Noise \" + noise_type + \" not recognized.\")\n",
    "                word_noised = word\n",
    "            words_noisy.append(word_noised)\n",
    "            n_changed += 1\n",
    "    return idx_noisy, words_noisy\n",
    "    \n",
    "\n",
    "in_data = \"../data/NoMusic/NorSID/nb.projectedTrain.conll.fixed\"\n",
    "alphabet = alphabet(in_data, 1)\n",
    "\n",
    "noise_lvl = 0.90\n",
    "\n",
    "for random_run in [\"a\",]:# \"b\", \"c\"]:\n",
    "    lines = []\n",
    "    with open(in_data) as f_in:\n",
    "        sentence = []\n",
    "        for line in f_in:\n",
    "            if line[0] == \"#\":\n",
    "                lines.append(line)\n",
    "                sentence = []\n",
    "            elif not line.strip():\n",
    "                if sentence:\n",
    "                    words = [token_details[1] for token_details in sentence]\n",
    "                    idx_noisy, words_noisy = add_random_noise(words, noise_lvl, alphabet)\n",
    "                    for i, word in zip(idx_noisy, words_noisy):\n",
    "                        sentence[i][1] = word\n",
    "                    for token_details in sentence:\n",
    "                        lines.append(\"\\t\".join(token_details))\n",
    "                sentence = []\n",
    "                lines.append(line)\n",
    "            else:\n",
    "                sentence.append(line.split(\"\\t\"))\n",
    "    with open(f\"../data/nb_projectedTrain_noise_{noise_lvl}{random_run}.conll\", \"w+\") as f_out:\n",
    "        for line in lines:\n",
    "            f_out.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e746244f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 4]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(idx_noisy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
